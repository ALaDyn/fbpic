\documentclass[a4paper]{article}   	% use "amsart" instead of "article" for AMSLaTeX format

\usepackage{geometry}               	
\geometry{a4paper,margin=1.1in}           % ... or a4paper or a5paper or ... 

%\usepackage{graphicx}			

\usepackage{amsmath}
\usepackage{tikz}

\usepackage{hyperref}
\hypersetup{colorlinks=true,
    citecolor=blue,    filecolor=blue,
    linkcolor=blue,     urlcolor=blue
}
%\usepackage{cite}
\usepackage{natbib}

\newcommand{\ir}{\frac{1}{r}}
\newcommand{\Integ}[1]{\int_{-\infty}^{\infty} \!\!\!\!\!\!\!\!
  \mathrm{d}#1}
\newcommand{\RInteg}[1]{\int_{0}^{\infty} \!\!\!\!\!\!\! #1\mathrm{d}#1}
\newcommand{\rInteg}{\int_{0}^{r_{max}} \!\!\!\!\!\!\! r\mathrm{d}r}
\newcommand{\TInteg}[1]{\int_{0}^{2\pi} \!\!\!\!\!\!\!\! \mathrm{d}#1}

\newcommand{\tB}[2]{\spectral{B}_{#1,m}^{#2}}
\newcommand{\tE}[2]{\spectral{E}_{#1,m}^{#2}}
\newcommand{\tj}[2]{\spectral{J}_{#1,m}^{#2}}

\newcommand{\trho}[1]{\spectral{\rho}_{m}^{#1}}

\renewcommand{\vec}[1]{\boldsymbol{#1}}

\newcommand{\comment}[1]{\textcolor{red}{#1}}

\newcommand{\spectral}[1]{\hat{\mathcal{#1}}}

% Reference automatique aux equations, sections, figures
\usepackage{cleveref}

\title{A pseudo-spectral, cylindrical and dispersion-free Particle-In-Cell algorithm}
%\pagestyle{empty}
\author{R\'emi \textsc{Lehe}, Manuel \textsc{Kirchen}, Igor \textsc{Andriyash}, Jean-Luc \textsc{Vay}}

\begin{document}

\maketitle

\section*{Introduction}

\comment{ Introduce finite difference in the intro.}

Particle-In-Cell (PIC) algorithms\citep{Birdsall2004,Hockney1988} 
are extensively used in several areas of physics, including the study
of astrophysical plasmas and fusion plasmas,
as well as for laser-plasma interactions and accelerator physics. Yet,
despite their wide use, PIC algorithms remain very computationally
demanding and are still subject to a range of numerical artifacts. 
These shortcomings can be particularly significant for
simulations of accelerated particle beams and of 
laser-plasma interactions (such as laser-wakefield acceleration). 
This is mainly for two reasons:
\begin{itemize}
\item In these cases, the system often has close-to-cylindrical
  symmetry (e.g. particle beams and laser pulses are often
  cylindrically symmetric). This prevents the use of 2D Cartesian 
PIC algorithms (which are only well-suited for slab-like symmetry),
and is instead often dealt with by using
  3D Cartesian PIC algorithms. However, 3D PIC algorithms are extremely
  computationally intensive.
\item The physical objects of interest (e.g. the laser, or the
  accelerated particle beam) often propagate close to the speed of
  light. This makes them very sensitive to \emph{numerical
    dispersion}, i.e. the fact that the electromagnetic waves do not
  propagate exactly at the physical speed of light in a standard PIC
  code, but propagate instead at an spuriously-altered,
  resolution-dependent speed. In the above-mentioned cases, 
numerical dispersion can lead to substantial numerical artifacts
which can mask or disrupt the physics at stake in the simulation. This
includes for instance numerical Cherenkov effect in general
\citep{GodfreyJCP1974}, but also more specific artifacts, such as
e.g. the erroneous prediction of the dephasing length in
laser-wakefield acceleration \citep{CowanPRSTAB2013}.

\end{itemize}
Yet several improvements can be made to the PIC algorithm, in order
to mitigate these difficulties and increase the speed and
accuracy of PIC algorithms in these situations. 
\begin{itemize}
\item One of these improvements was introduced by the recent
  development of cylindrically-symmetric
PIC algorithms with azimuthal decomposition \citep{Lifschitz,Davidson} (also
refered to as \emph{quasi-3D} algorithms). By taking
into account the symmetry of the system, these algorithms can typically reduce
the cost of the simulation to a few times that of a 2D Cartesian simulation,
instead of that of a full 3D Cartesian simulation. Moreover, unlike 2D
Cartesian algorithms, these algorithms are well adapted to close-to-cylindrical
physical systems and can accurately capture physical effects that are intrisically
3D (such as e.g. the non-linear self-focusing of an intense laser in a
plasma \citep{EsareyRMP2009}).

\item A second, separate improvement was introduced by spectral
Cartesian PIC algorithms \citep{BunemanJCP1980,DawsonRMP1983},
i.e. algorithms that solve the Maxwell equations in Fourier
space. There is indeed a class of spectral algorithms -- often refered to
as \emph{Pseudo-Spectral Analytical Time Domain} (PSATD) algorithms 
\citep{Haber} -- which exhibits no numerical dispersion whatsoever. As a
consequence, these algorithms are free from the numerical artifacts
associated with the spurious speed of the electromagnetic waves in PIC
codes. Moreover, it was shown recently
\citep{XuJCP2013,YuJCP2014,YuCPC2015,
GodfreyIEEE2014,GodfreyJCP2014} 
that spectral PIC algorithms have better stability properties when 
performing PIC simulations in
a Lorentz-boosted frame \citep{VayPRL2007,MartinsNatPhys2010}. 
These stability properties are very
promising since boosted-frame simulations can be faster than 
their laboratory-frame counterparts by several orders of magnitude \citep{VayPRL2007}.
\end{itemize}

Even though these two improvements are both very valuable, they cannot be
combined with one another in their present
formulation. This is because the \emph{quasi-3D} algorithm uses a
cylindrical system of coordinates, whereas the spectral PIC algorithms
(and in particular the \emph{PSTAD} algorithms)
were developped in a Cartesian system of coordinates. This
incompatibility is however not definitive, and the aim of this article
is to overcome these differences by developping a \emph{spectral
  cylindrical} formalism. In this document, we derive this formalism,
and we show that it can be used to build a PIC algorithm that combines 
the speed of \emph{quasi-3D} algorithms with
the accuracy and lack of numerical dispersion of the \emph{PSATD} algorithms.

Although the algorithm described here is, to our knowledge, unique in
its capabilities, there are several other PIC algorithms that use 
a similar -- yet not equivalent -- approach. One such example is the
hybrid, cylindrical version of \textsc{OSIRIS} \citep{Yuarxiv2015}. This algorithm
involves a Fourier transform in the longitudinal direction, but
retains a finite-difference formulation in the transverse (radial)
direction. As a consequence, this algorithm is not fully spectral, nor
fully dispersion-free. Another such example is the PIC code \textsc{PlaRes} 
\citep{AndriyashJCP2015}, which also uses a spectral cylindrical
formalism but relies on the scalar and vector potentials
$\phi$ and $\vec{A}$ instead of the standard PIC formulation in terms
of $\vec{E}$ and $\vec{B}$. As a result, \textsc{PlaRes} differs from the
algorithm described here, both in the equations that it simulates and
in their numerical implementation.

In the present article, we start by deriving the equations of our
spectral cylindrical formalism (\cref{sec:theory}). We then explain
how these equations were discretized and implemented in a fully
working PIC code (\cref{sec:implementation}). We then report on the
results of a number of benchmarks that were performed with this PIC
code (\cref{sec:benchmarks}), and describe two typical physical situations in
which our spectral algorithm performs better than standard,
finite-difference algorithms (\cref{sec:advantages}).

\section{Representation of the fields and continuous equations}
\label{sec:theory}

\subsection{A reminder on spectral Cartesian codes}

It is well-known that the Maxwell equations in Cartesian coordinates 
\begin{align}
\frac{1}{c^2}\partial_t E_x = \partial_y B_z - \partial_z B_y - \mu_0  j_x \qquad&   
\partial_t B_x = -\partial_y E_z + \partial_z E_y \label{eq:CartMaxwellx} \\
\frac{1}{c^2}\partial_t E_y = \partial_z B_x - \partial_x B_z - \mu_0  j_y \qquad &   
\partial_t B_y = -\partial_z E_x + \partial_x E_z \label{eq:CartMaxwelly}  \\
\frac{1}{c^2}\partial_t E_z = \partial_x B_y - \partial_y B_x - \mu_0  j_z \qquad &   
\partial_t B_z = -\partial_x E_y + \partial_y E_x \label{eq:CartMaxwellz} 
\end{align}
can be solved by representing the fields as a sum of Fourier modes.
\begin{equation}
\label{eq:CartBwTrans}
F_u(\vec{r}) = \frac{1}{(2\pi)^{3}}\Integ{k_x} \,\Integ{k_y}\,
\Integ{k_z} \; \mathcal{F}_u(\vec{k}) \, e^{i(k_x x + k_y y + k_z z)} 
\end{equation}
with 
\begin{equation}
\label{eq:CartFwTrans}
\mathcal{F}_u(\vec{k})  = \Integ{x} \,\Integ{y}\, \Integ{z} \;
F_u(\vec{r}) \, e^{-i(k_x x + k_y y + k_z z)} 
\end{equation}
where $F$ is any of the fields $E$, $B$ or $j$, and where $u$ is
either $x$, $y$ or $z$. $\mathcal{F}$ represents the Fourier
components of $F$, which will be denoted
$\mathcal{E}$, $\mathcal{B}$ or $\mathcal{J}$ depending on whether
$F$ represents $E$, $B$ or $j$. With this representation, the
different Fourier modes decouple and the equations 
\cref{eq:CartMaxwellx,eq:CartMaxwelly,eq:CartMaxwellz} become 
\begin{align}
\frac{1}{c^2}\partial_t \mathcal{E}_x = ik_y \mathcal{B}_z - ik_z \mathcal{B}_y - \mu_0 \mathcal{J}_x \qquad &   
\partial_t \mathcal{B}_x = -ik_y \mathcal{E}_z + ik_z \mathcal{E}_y \label{eq:CartSpectMaxwellx}\\
\frac{1}{c^2}\partial_t \mathcal{E}_y = ik_z \mathcal{B}_x - ik_x \mathcal{B}_z - \mu_0  \mathcal{J}_y \qquad &   
\partial_t \mathcal{B}_y = -ik_z \mathcal{E}_x + ik_x \mathcal{E}_z \label{eq:CartSpectMaxwelly}\\
\frac{1}{c^2}\partial_t \mathcal{E}_z = ik_x \mathcal{B}_y - ik_y \mathcal{B}_x - \mu_0 \mathcal{J}_z  \qquad &   
\partial_t \mathcal{B}_z = -ik_x \mathcal{E}_y + ik_y \mathcal{E}_x \label{eq:CartSpectMaxwellz}
\end{align}
The Fourier coefficients can then be integrated in time, and
transformed back into real space using \cref{eq:CartBwTrans}. This is
the core principle of spectral Cartesian algorithms, including the PSATD algorithms.

\subsection{Spectral cylindrical representation}

The Fourier representation \cref{eq:CartBwTrans} is no longer the
appropriate representation when the Maxwell equations are written in cylindrical coordinates.
\begin{align}
\frac{1}{c^2}\partial_t E_r = \ir \partial_\theta B_z - \partial_z B_\theta - \mu_0  j_r \qquad&   
\partial_t B_r = -\ir \partial_\theta E_z + \partial_z E_\theta \label{eq:CircMaxwellr} \\
\frac{1}{c^2}\partial_t E_\theta = \partial_z B_r - \partial_r B_z - \mu_0  j_\theta \qquad &   
\partial_t B_\theta = -\partial_z E_r + \partial_r E_z \label{eq:CircMaxwellt}  \\
\frac{1}{c^2}\partial_t E_z = \ir\partial_r r B_\theta - \ir\partial_\theta B_r - \mu_0  j_z \qquad & 
\partial_t B_z = -\ir\partial_r r E_\theta + \ir\partial_\theta E_r \label{eq:CircMaxwellzz} 
\end{align}
When replacing
\cref{eq:CartBwTrans} into the \cref{eq:CircMaxwellr,eq:CircMaxwellt,eq:CircMaxwellzz}, the Fourier modes do not decouple. Instead one has to use the Fourier-Bessel representation.
\begin{align}
& F_z(\vec{r}) = \frac{1}{(2\pi)^2}\!\!\!\sum_{m=-\infty}^{\infty} \Integ{k_z}
\RInteg{k_\perp }\; \spectral{F}_{z,m}(k_z,k_\perp ) \; J_m(k_\perp r)\, e^{-im\theta + ik_z z} 
\label{eq:CircBwTransz} \\
& F_r(\vec{r}) = \frac{1}{(2\pi)^2}\!\!\!\sum_{m=-\infty}^{\infty} \Integ{k_z}\,\RInteg{k_\perp }\;
\left( \spectral{F}_{+,m}(k_z,k_\perp )\; J_{m+1}(k_\perp r) +\spectral{F}_{-,m}(k_z,k_\perp )\; J_{m-1}(k_\perp r)
\right)  e^{-im\theta +ik_z z}
\label{eq:CircBwTransr} \\
& F_\theta(\vec{r}) = \frac{1}{(2\pi)^2}\!\!\!\sum_{m=-\infty}^{\infty} \Integ{k_z}\,\RInteg{k_\perp }\;
i\left( \spectral{F}_{+,m}(k_z,k_\perp )\; J_{m+1}(k_\perp r) - \spectral{F}_{-,m}(k_z,k_\perp )\; J_{m-1}(k_\perp r)
\right)  e^{-im\theta +ik_z z} 
\label{eq:CircBwTranst}
\end{align}
where $F$ is either $E$, $B$ or $j$, where $J_m$ denotes the Bessel
function of order $m$, and where $\spectral{F}_{z,m}$, $\spectral{F}_{+,m}$ and
 $\spectral{F}_{-,m}$ represent the spectral components of $F$. These spectral components are given by:
\begin{align}
\spectral{F}_{z,m}(k_z,k_\perp ) &= \Integ{z} \RInteg{r}
\TInteg{\theta} \;F_z(\vec{r})\; J_m(k_\perp r) e^{im\theta
 - i k_z z} \label{eq:CircFwTransz} \\
\spectral{F}_{+,m}(k_z,k_\perp ) &= \Integ{z} \RInteg{r}
\TInteg{\theta} \;\frac{F_r (\vec{r})-iF_\theta (\vec{r})}{2}\; J_{m+1}(k_\perp r) e^{im\theta
 - i k_z z} \label{eq:CircFwTransp} \\
\spectral{F}_{-,m}(k_z,k_\perp ) &= \Integ{z} \RInteg{r}
\TInteg{\theta} \;\frac{F_r (\vec{r})+iF_\theta(\vec{r})}{2}\; J_{m-1}(k_\perp r) e^{im\theta
 - i k_z z} \label{eq:CircFwTransm} 
\end{align}
\noindent Notice here that the Cartesian
component $F_z$ and cylindrical components
$F_r$, $F_\theta$ do not transform in the same manner, which is due
to their different behavior close to the axis. (See
\cref{sec:CircTrans} for a derivation of the above equations.) 
Note also that scalar fields (like $\rho$) transform in the
same way as the Cartesian component $F_z$. 

When replacing \cref{eq:CircBwTransr,eq:CircBwTranst,eq:CircBwTransz} into the Maxwell equations in cylindrical
coordinates \cref{eq:CircMaxwellr,eq:CircMaxwellt,eq:CircMaxwellzz},
the different modes decouple, and the equations for the spectral
coefficients become:
\begin{align}
\frac{1}{c^2}\partial_t \spectral{E}_{+,m} = - \frac{ik_\perp }{2}\spectral{B}_{z,m} + k_z\spectral{B}_{+,m} - \mu_0\spectral{J}_{+,m} \qquad &   
\partial_t \spectral{B}_{+,m} = \frac{ik_\perp }{2} \spectral{E}_{z,m} - k_z
\spectral{E}_{+,m} 
\label{eq:CircMaxwellp} \\
\frac{1}{c^2}\partial_t \spectral{E}_{-,m} = -\frac{ik_\perp }{2} \spectral{B}_{z,m} - k_z \spectral{B}_{-,m} - \mu_0  \spectral{J}_{-,m} \qquad &   
\partial_t \spectral{B}_{-,m} = \frac{ik_\perp }{2} \spectral{E}_{z,m} + k_z
\spectral{E}_{-,m} \label{eq:CircMaxwellm} \\
\frac{1}{c^2}\partial_t \spectral{E}_{z,m} = ik_\perp  \spectral{B}_{+,m} + ik_\perp \spectral{B}_{-,m}  - \mu_0 \spectral{J}_{z,m}  \qquad & 
\partial_t \spectral{B}_{z,m} = -ik_\perp  \spectral{E}_{+,m} - ik_\perp \spectral{E}_{-,m}  \label{eq:CircMaxwellz} 
\end{align}
(See \cref{sec:SpectMaxwell} for a derivation of these equations.)
Notice that these equations have a similar structure as 
\cref{eq:CartSpectMaxwellx,eq:CartSpectMaxwelly,eq:CartSpectMaxwellz}, as 
they also involve the product of the fields with the components of
$\vec{k}$, in their right-hand side. They do differ however in their
details, as evidenced by the signs, the factors 1/2 and the
presence or absence of the complex number $i$ in some terms.

Similarly, in this formalism, the conservation equations
$\vec{\nabla}\cdot\vec{E}=\rho/\epsilon_0$ and
$\vec{\nabla}\cdot\vec{B} = 0$
become
\begin{equation}
\label{eq:SpectCons}
k_\perp (\spectral{E}_{+,m} -\spectral{E}_{-,m}) + ik_z \spectral{E}_{z,m} =
\frac{\spectral{\rho}_m}{\epsilon_0} \qquad
 k_\perp (\spectral{B}_{+,m} -\spectral{B}_{-,m}) + ik_z \spectral{B}_{z,m} =
0 \end{equation}
As expected, the above conservation equations are
preserved by the Maxwell equations
\cref{eq:CircMaxwellp,eq:CircMaxwellm,eq:CircMaxwellz}, provided
that the current satisfies $\partial_t
\rho + \vec{\nabla} \cdot \vec{j} = 0$, i.e. in spectral space:
\begin{equation}
\label{eq:SpectCharge}
\partial_t \spectral{\rho}_m + k_\perp (\spectral{J}_{+,m} -\spectral{J}_{-,m}) + ik_z
\spectral{J}_{z,m} = 0
\end{equation}  

As in a spectral Cartesian PIC codes, the equations
\cref{eq:CircMaxwellp,eq:CircMaxwellm,eq:CircMaxwellz}  
can be integrated in time, and the fields can then be transformed back into
real space, using \cref{eq:CircBwTransz,eq:CircBwTransr,eq:CircBwTranst}. Therefore,
the methods used to integrate the fields in time in a spectral Cartesian
code (e.g. PSATD) should be transposable to this spectral cylindrical formalism.

However, the advantage of this formalism over its Cartesian
counterpart is that the sum over $m$ in
\cref{eq:CircBwTransz,eq:CircBwTransr,eq:CircBwTranst} can generally
be truncated to only a few terms, for physical situations that have
close-to-cylindrical symmetry \citep{Lifschitz}. This is because the
different values of $m$ correspond to different azimuthal modes of the
form $e^{-im\theta}$, and because these modes are typically zero for
large values of $|m|$, in situations with close-to-cylindrical symmetry.
As a result, the representation of the fields is
reduced to a few 2D arrays $\spectral{F}_m(k_z,k_\perp )$ instead of the
Cartesian 3D arrays $\mathcal{F}(k_x,k_y,k_z)$. This reduction makes
the manipulation of the fields much more computationally efficient.

\section{Numerical implementation}
\label{sec:implementation}

\subsection{Overview of the algorithm}

The PIC algorithm described here uses the above-mentioned representation
of the fields. Although the fields are represented by a few
2D arrays, the particles are still distributed in 3D and their motion
is integrated in 3D Cartesian coordinates. However, due to the
lower number of cells in a 2D array, one can drastically reduce the
total number of particles and still have significative statistics for
each cell.

Similarly to a spectral Cartesian code, we do not perform the
current deposition and field gathering directly from the
macroparticles to the spectral space. (This is inefficient since the
deposition and gathering are local operations in real space -- i.e. affect
only the few cells next to the macroparticle -- but global operations
in spectral space -- i.e. they affect all the spectral modes
simultaneously.) Instead we use an intermediate grid where these
operations can be performed locally, and where the fields $\hat{F}_{u,m}$
are defined by
\begin{equation} 
\label{eq:IntermBwTrans}
F_u(\vec{r}) = \sum_{m=-\infty}^{\infty} \hat{F}_{u,m}(r,z)
e^{-im\theta} 
\end{equation}
\begin{equation}
\label{eq:IntermFwTrans}
\hat{F}_{u,m}(r,z) = \frac{1}{2\pi} \TInteg{\theta} \;
F_u(\vec{r})e^{im\theta}
\end{equation}
where ${F}$ is either ${E}$, ${B}$ or
${j}$ and $u$ is either $z$, $r$ or $\theta$. Notice that this representation is the
same as that of \citep{Lifschitz, Davidson}. In this
representation, the spectral decomposition in the azimuthal
direction is preserved, since the factors $e^{im\theta}$ can be efficiently computed from the
particle Cartesian positions $x,y,z$ by using the relation $e^{im\theta} = (x+iy)^m/r^m$
\citep{Lifschitz}.

After the particles deposit their charge and current onto this
intermediate grid, the fields of the grid are transformed into spectral
space where the Maxwell equations can be easily integrated. From
\cref{eq:IntermFwTrans,eq:IntermBwTrans} and
\cref{eq:CircFwTransz,eq:CircFwTransp,eq:CircFwTransm,eq:CircBwTransz,eq:CircBwTransr,eq:CircBwTranst}, 
the transformation between the intermediate grid $\hat{F}_{m}(r,z)$
and the spectral grid $\spectral{F}_m(k_\perp, k_z)$ is:
\begin{align}
\spectral{F}_{z,m}(k_\perp,k_z) & = \mathrm{HT}_{m} [ \; \mathrm{FT}
                               [ \; \hat{F}_{z,m}(r,z) \; ] \;] \\
\spectral{F}_{+,m}(k_\perp,k_z) &= \mathrm{HT}_{m+1}\left[ \; \mathrm{FT} \left[ \frac{
  \hat{F}_{r,m} -i  \hat{F}_{\theta,m} }{2}  \right] \;\right] \\
\spectral{F}_{-,m}(k_\perp,k_z) &= \mathrm{HT}_{m-1} \left[ \;\mathrm{FT} \left[ \frac{
  \hat{F}_{r,m} +i  \hat{F}_{\theta,m} }{2}  \right] \;\right] 
\end{align}
and
\begin{align}
\hat{F}_{z,m}(r,z) &= \mathrm{IFT} [\; \mathrm{IHT}_{m} [
                         \spectral{F}_{z,m}(k_\perp,k_z) ] \; ] \\
\hat{F}_{r,m}(r,z) & = \mathrm{IFT} \left[ \; \mathrm{IHT}_{m+1}
                         [ \spectral{F}_{+,m}(k_\perp,k_z) ] + \mathrm{IHT}_{m-1} [
                         \spectral{F}_{-,m}(k_\perp,k_z) ] \; \right] \label{eq:FTHTr}\\
\hat{F}_{\theta,m}(r,z) & = i\;\mathrm{IFT} \left[ \; \mathrm{IHT}_{m+1}
                         [ \spectral{F}_{+,m}(k_\perp,k_z) ] -
                          \mathrm{IHT}_{m-1} [
                          \spectral{F}_{-,m}(k_\perp,k_z) ] \; \right]
\label{eq:FTHTt}
\end{align}
where $\mathrm{FT}$ represents a Fourier Transform along the $z$
axis and $\mathrm{HT}_{n}$ represents a Hankel Transform of order
$n$ along the transverse $r$ axis, and where $\mathrm{IFT}$ and
$\mathrm{IHT}_{n}$ represent the corresponding inverse
transformations:
\[ \mathrm{FT} [f]\, (k_z) \equiv \Integ{z} \, e^{-ik_zz} \; f(z) \qquad 
\mathrm{IFT} [g] \,(z)\equiv \frac{1}{2\pi}\Integ{k_z} \, e^{ik_zz} \;  g(k_z)\]
\[ \mathrm{HT}_{n} [f]\,(k_\perp) \equiv 2\pi \RInteg{r} \,
J_{n}(k_\perp r) \; f(r) \qquad 
\mathrm{IHT}_{n} [g]\,(r) \equiv \frac{1}{2\pi}\RInteg{k_\perp} \,  J_{n}(k_\perp r)  \;  g(k_\perp) \]

The above equations show that the transformation from the intermediate
grid ($\hat{F}_{u,m}$) to the spectral grid ($\spectral{F}_{u,m}$) is
the combination of a Fourier transform (in $z$) and a Hankel transform
(in $r$). The Fourier transform in $z$ can be implemented through a Fast Fourier
Transform (FFT) algorithm, which imposes to use an evenly-spaced grid
in $z$ and in $k_z$. On the other hand, there is more freedom of
choice for the Discrete Hankel Transform (DHT), and the implementation that
we chose is described in the next section
(\cref{sec:discretization}) and in the appendix \ref{sec:HTMatrix}.

\Cref{fig:GlobalScheme} gives an overview of the successive steps
involved in one PIC cycle, including the
respective role of the intermediate and spectral grid. Note that, in the PSATD
scheme that we chose (and which is described in more details in
\cref{sec:FieldIntegration}), all the fields are defined at integer
timesteps, except for the currents, which are defined at half
timesteps. The following subsections describe the successive steps of
the PIC cycle in more details.

\begin{figure}
\input{figures/PIC-cycle.tex}
\caption{Description of the PIC cycle \label{fig:GlobalScheme}
  \comment{More information in caption}}
\end{figure}


\subsection{Transverse discretization of the intermediate grid, of the spectral grid
  and of the Hankel Transform}
\label{sec:discretization}

When transforming from the intermediate to the spectral grid, the FFT
algorithm is the natural way to discretize the Fourier transform along $z$, due to its
favorable computational scaling ($\propto N_z\log(N_z)$).
On the other hand, there are a variety of existing algorithms (that are not mathematically
equivalent) to discretize the Hankel
transform (e.g. \citep{Cree,Yu,Siegman,Guizar,KaiMing}), and the use of one or the other
is very dependent on the pursued application. Broadly
speaking, chosing an algorithm for the Discrete Hankel Transform (DHT)
algorithms consists in 
\begin{itemize}
\item Choosing a discrete grid in $r$ and $k_\perp$ space, on which to
  sample the functions to be transformed. In some algorithms, these
  grids may not be evenly-spaced, and can be for instance
  logarithmically spaced \citep{Siegman} or correspond to the zeros of
  Bessel functions \citep{Yu,Guizar,KaiMing}.
\item Once a grid is chosen, the DHT amounts to a linear operation on a
  finite set of points (the points of the grid) and can thus be
  represented by a matrix. Thus the second choice is that of a matrix
  that represents, as closely as possible, the exact Hankel Transform.
\end{itemize}
Here, we choose to discretize the algorithm on an evenly-spaced grid in $r$
(for the intermediate grid) :
\[ r_j = \Delta r \left( j+\frac{1}{2} \right) \qquad  j \in \{0, ...,
N_r-1 \} \qquad \mathrm{where} \quad \Delta r = \frac{r_{max}}{N_r} \]
but on an irregular grid in $k_\perp$ (for the spectral grid). This is because the authorized
$k_\perp$ are determined by the boundary conditions, in the same way that
the periodic boundaries in a Cartesian code impose the use of
evenly-spaced $k$. Here, for simplicity, we impose that the
longitudinal fields be $0$ at $r_{max}$ (i.e. $E_z(r_{max}, z) = 0$,
$B_z(r_{max}, z) = 0$). In this case, it turns out that the set of authorized
$k_\perp$ depends on the azimuthal mode $m$ and reads
\[  k^m_{\perp,j} = \frac{\alpha_j^m}{r_{max}} \qquad j \in \{0, ..., N_r-1 \}\]
where $\alpha^m_j$ is the $j$th positive zero of the Bessel function of order
$m$ $J_m$ (including the trivial value $\alpha_0^m=0$ for
$m>0$). These values are represented in figure \ref{fig:Kgrid}. Notice
that it is not an issue that the spectral components $\spectral{F}_m$
for different azimuthal modes $m$ are discretized on different
$k_\perp$ grids, since each azimuthal mode $m$ evolves separately in
\cref{eq:CircMaxwellp,eq:CircMaxwellm,eq:CircMaxwellz}.

\begin{figure}[!h]
\includegraphics[width=\textwidth]{figures/KGrid.pdf}
\caption{\label{fig:Kgrid}Position of the grid points in $k_\perp$ space
  (blue dots) for the azimuthal modes $m=0$, $m=1$ and $m=2$ for $N_r
  = 10$ and $r_{max}=1$. These values are compared with those of an
  evenly-spaced grid used in spectral Cartesian codes (grey dots, $k_j = j\pi/r_{max}$).}
\end{figure}

As mentioned above, once this grid is set up, the Discrete Hankel Transform is simply a
linear operation on a finite set of points, and can thus be
represented by a matrix operation
\comment{Change the notations for the matrices in the appendix}
\[ \mathrm{DHT^m_n}[f] \,(k^m_{\perp,j}) = \sum_{p=0}^{N_r-1} (M_{n,m})_{j,p}
\;f(r_p) \qquad \mathrm{IDHT^m_n}[g] \, (r_j) = \sum_{p=0}^{N_r-1}
(M'_{n,m})_{j,p} \; g(k^m_{\perp,p}) \]

Notice that the $N_r\times N_r$ transformation matrices $M_{n,m}$ and
$M_{n,m}'$ depend on $n$ (order of the Hankel transform) and $m$
(index of the azimuthal mode, and thus index of the spectral grid
$k^m_{\perp,j}$ on which the Hankel transform is performed). 
In practice, $n$ and $m$ are either equal or they differ by
$\pm 1$ (e.g. in \cref{eq:FTHTr,eq:FTHTt}, when the azimuthal mode $m$ is
transformed using the Hankel transform of order $m+1$ or $m-1$.)

The expressions of $M_{n,m}$ and $M'_{n,m}$, for the DHT algorithm that we chose, are given in
\cref{sec:HTMatrix}. %This particular choice is very specific and
%dependent on the imposed boundary conditions at $r_{max}$ ; in future
%work, different implementations of the DHT could be used depending on
%the boundary conditions. 
In practice,  these matrices need to be
computed only once (at the beginning of the simulation) and can then be used at each
iteration. Notice also that the computational time for this
matrix multiplication is proportional to $N_r^2$, which is slow
compared to a 1D FFT ($\propto N_r \log(N_r)$), but
still faster than the 2D FFT ($\propto N_x N_y \log(N_x) + N_x N_y \log(N_y) $)
which is typically used in a spectral 3D Cartesian code. 


\subsection{Field gathering}

When gathering the fields from the intermediate grid to the
macroparticles (see \cref{fig:GlobalScheme}),
we use the standard linear shape factors :
\begin{align} 
F_u(\vec{r}_k) &=  \sum_{p,q} S_{z,p}(z_k)S_{r,q}(r_k) \left[ \sum_{m=-N_m}^{N_m} \hat{F}_{u,m}(z_p, r_q)
  e^{-im\theta_k} \right] \\
& = \sum_{p,q} S_{z,p}(z_k)S_{r,q}(r_k) \left[ \hat{F}_{u,0}(z_p,
  r_q) + 2\,\Re \left( \sum_{m=1}^{N_m} \hat{F}_{u,m}(z_p, r_q)
  e^{-im\theta_k} \right) \right] \label{eq:gathering}
\end{align}
where $F$ is either $E$ or $B$, $u$ is either $r$, $\theta$ or $z$, $k$ is the index of the macroparticle,
and $p$ and $q$ are the indices of the two nearest cells in $z$ and
$r$ respectively. $N_m$ is the total number
of azimuthal modes used. Notice that, in \cref{eq:gathering}, we used the fact that
$\hat{F}_{u,-m}(z,r) = \hat{F}^*_{u,m}(z,r) $, which can be
inferred from \cref{eq:IntermFwTrans}. Incidentally, \cref{eq:gathering} shows that only the modes
with $m\geq 0$ need to be taken into account in the code, as they are 
sufficient to retrieve the force on the macroparticles.

Finally, in \cref{eq:gathering}, $S_{z,p}$ and $S_{z,q}$ are the linear
shape factors in $z$ and $r$ :
\[ S_{z,p_0}(z) = \frac{z_{p_0+1}- z}{\Delta z}  \qquad 
S_{z,p_0 +1}(z) = \frac{ z - z_{p_0} }{\Delta z} \qquad
\mathrm{with} \quad z_{p_0} \leq z < z_{p_0 +1}  \]
\[ S_{r,q_0}(r) = \frac{ r_{q_0+1} - r }{  \Delta r }
\qquad S_{r,q_0+1}(r) = \frac{ r - r_{q_0} }{  \Delta r }
\qquad \mathrm{with} \quad r_{q_0} \leq r < r_{q_0+1}
 \]

\comment{Add shape factor close to the axis}

\subsection{Equations of motion}

Since the macroparticles are evolved in 3D, we compute
the Cartesian components $E_x$, $E_y$, $E_z$, $B_x$, $B_y$ and
$B_z$, from the fields $E_r$, $E_\theta$, $E_z$, $B_r$, $B_\theta$ and
$B_z$ that were gathered at the positions of each macroparticle. 
We then advance the equations of motion
\[ \frac{d\vec{p}}{dt} = q\vec{E} + q\vec{v}\times \vec{B} \qquad
\frac{d\vec{x}}{dt} = \frac{\vec{p}}{\gamma \,m} \]
\noindent  in standard 3D Cartesian coordinates, by using the leap-frog pusher described in \citep{VayPoP2008}.

\subsection{Current deposition}

As in \citep{Lifschitz}, the charge density is calculated on the intermediate grid in the
following way:
\[ \hat{\rho}_m(z_p,r_q) = \frac{ \sum_k  S_{z,p}(z_k)S_{r,q}(r_k) Q_k e^{im\theta_k}}{V_{q}} \]
where $Q_k$ is the charge of the macroparticle with index $k$, and
where $V_q$ is the volume of a cell, which is for our grid
\[ V_{q} = \pi [\, (q+1)^2- q^2\,] \Delta r^2 \Delta z \]

\noindent Similarly, the current deposition is given by
\[ \hat{j}_{u,m}(z_p,r_q) = \frac{\sum_k S_{z,p}(z_k) S_{r,q}(r_k)
Q_k v_{u,k} e^{im\theta_k}}{V_{q}} \]
where $u = z,r,\theta$ and the $v_{u,k}$ are the cylindrical components of the
velocity of the macroparticle $k$. As mentioned previously, once the
macroparticles have deposited their charge and current on the
intermediate grid, we transform them to the spectral grid, using an
FFT and a DHT (see \cref{fig:GlobalScheme}).

Notice that we do not attempt to
reproduce the Esirkepov current deposition here \citep{Esirkepov}, and instead use a
simple direct current deposition. It is well-known that his simple deposition does not necessarily
satisfy the relation $\partial_t\rho + \vec{\nabla}\cdot\vec{j} =
0$, but that this can be corrected for, by slightly modifying the
currents without modifying their curl:
\[ \vec{j}' = \vec{j} - \vec{\nabla} G \]
where $G$ satisfies the Poisson-like equation
\[ \vec{\nabla}^2 G = \partial_t\rho + \vec{\nabla}\cdot\vec{j} \]

The above equation is typically expensive to solve on a spatial grid, but
very easy to solve in spectral space. In spectral space and with the
notations of \cref{fig:GlobalScheme}, these equations become
\[ \spectral{J}'^{n+1/2}_{+,m} = \spectral{J}^{n+1/2}_{+,m} +
\frac{k_\perp}{2} \spectral{G}^{n+1/2}_m
\qquad
\spectral{J}'^{n+1/2}_{-,m} = \spectral{J}^{n+1/2}_{-,m} - \frac{k_\perp}{2} \spectral{G}^{n+1/2}_m
\qquad \spectral{J}'^{n+1/2}_{z,m} = \spectral{J}^{n+1/2}_{z,m} - ik_z
\spectral{G}^{n+1/2}_m\]
with
\[ \spectral{G}^{n+1/2}_m = - \frac{1}{k_\perp^2 + k_z^2}\left(
  \frac{\spectral{\rho}^{n+1}_m -\spectral{\rho}^{n}_m}{\Delta t} + k_\perp
  (\spectral{J}^{n+1/2}_{+,m} -\spectral{J}^{n+1/2}_{-,m}) + ik_z\spectral{J}^{n+1/2}_{z,m}  \right) \]
With this correction, the new currents $\spectral{J}'^{n+1/2}$ do satisfy
the charge conservation equation \cref{eq:SpectCharge}. Therefore we apply this
correction in spectral space, at the end of the current deposition at each timestep.

\comment{Mention smoothing in k space}

\subsection{Integration of the Maxwell equation using the PSATD scheme}
\label{sec:FieldIntegration}

The Maxwell equations
\cref{eq:CircMaxwellp,eq:CircMaxwellm,eq:CircMaxwellz} could in
principle be integrated in time by using a finite difference scheme:
\begin{align*}
\tE{+}{n+1} = \; & \tE{+}{n} + 
c^2\Delta t\left(-\frac{ik_\perp }{2} \tB{z}{n} + k_z\tB{+}{n}
- \mu_0 \tj{+}{n+1/2} \right) & \\
\tE{-}{n+1} =\; & \tE{-}{n} +
c^2\Delta t\left(- \frac{ik_\perp }{2} \tB{z}{n} - k_z\tB{-}{n}
- \mu_0 \tj{-}{n+1/2} \right) &\\
\tE{z}{n+1} =\; & \tE{z}{n} + 
c^2\Delta t\left(ik_\perp \tB{+}{n} + ik_\perp \tB{-}{n}
- \mu_0 \tj{z}{n+1/2} \right)  &
\end{align*}
\begin{align*}
\tB{+}{n+1} = \; & \tB{+}{n} - 
\Delta t\left(-\frac{ik_\perp }{2} \tE{z}{n} + k_z\tE{+}{n}
\right) & \\
\tB{-}{n+1} =\; & \tB{-}{n} - 
\Delta t\left(- \frac{ik_\perp }{2} \tE{z}{n} - k_z\tE{-}{n}
\right) &\\
\tB{z}{n+1} =\; & \tB{z}{n} - 
\Delta t\left(ik_\perp \tE{+}{n} + ik_\perp \tE{-}{n}
\right) &
\end{align*}
However, this type of scheme retains some amount of numerical dispersion, and can
thus affect the simulated physics.

Instead, here we use an adaptation of the PSATD scheme \citep{Haber} for the
Fourier-Bessel spectral space. As in the case of the standard
PSATD, we assume that the currents are constant over one timestep and
that the charge density is linear in time over the same timestep. Under these
assumptions, the Maxwell equations \cref{eq:CircMaxwellp,eq:CircMaxwellm,eq:CircMaxwellz} can be integrated
analytically over that timestep, and they lead to:
\begin{align*}
\tE{+}{n+1} = \; & C \tE{+}{n} + 
c^2\frac{S}{\omega}\left(-\frac{ik_\perp }{2} \tB{z}{n} + k_z\tB{+}{n}
- \mu_0 \tj{+}{n+1/2} \right) + \frac{c^2}{\epsilon_0}
\frac{k_\perp}{2}\left[ \frac{\trho{n+1}}{\omega^2}\left(
  1 - \frac{S}{\omega\Delta t}\right) -
\frac{\trho{n}}{\omega^2}\left( C -\frac{S}{\omega\Delta t}\right)\right]  & \\
\tE{-}{n+1} =\; & C \tE{-}{n} +
c^2\frac{S}{\omega}\left(- \frac{ik_\perp }{2} \tB{z}{n} - k_z\tB{-}{n}
- \mu_0 \tj{-}{n+1/2} \right) - \frac{c^2}{\epsilon_0}
\frac{k_\perp}{2}\left[ \frac{\trho{n+1}}{\omega^2}\left(
  1 - \frac{S}{\omega\Delta t}\right) - \frac{\trho{n}}{\omega^2}
\left( C - \frac{S}{\omega\Delta t}\right)\right]  &\\
\tE{z}{n+1} =\; & C \tE{z}{n} + 
c^2\frac{S}{\omega}\left(ik_\perp \tB{+}{n} + ik_\perp \tB{-}{n}
- \mu_0 \tj{z}{n+1/2} \right) - \frac{c^2}{\epsilon_0}
ik_z\left[ \frac{\trho{n+1}}{\omega^2}\left(
  1 - \frac{S}{\omega\Delta t}\right) - \frac{\trho{n}}{\omega^2}
\left( C - \frac{S}{\omega\Delta t}\right)\right]  &
\end{align*}
\begin{align*}
\tB{+}{n+1} = \; & C \tB{+}{n} - 
\frac{S}{\omega}\left(-\frac{ik_\perp }{2} \tE{z}{n} + k_z\tE{+}{n}
\right) + \mu_0 c^2\frac{1-C}{\omega^2} \left( -\frac{ik_\perp }{2}
  \tj{z}{n+1/2} + k_z \tj{+}{n+1/2} \right)& \\
\tB{-}{n+1} =\; & C \tB{-}{n} - 
\frac{S}{\omega}\left(- \frac{ik_\perp }{2} \tE{z}{n} - k_z\tE{-}{n}
\right) + \mu_0 c^2\frac{1-C}{\omega^2} \left( - \frac{ik_\perp }{2}
  \tj{z}{n+1/2} - k_z \tj{-}{n+1/2} \right) &\\
\tB{z}{n+1} =\; & C \tB{z}{n} - 
\frac{S}{\omega}\left(ik_\perp \tE{+}{n} + ik_\perp \tE{-}{n}
\right) + \mu_0 c^2\frac{1-C}{\omega^2} \left( ik_\perp
  \tj{+}{n+1/2} + ik_\perp \tj{-}{n+1/2} \right)&
\end{align*}

\noindent where $\omega \equiv c\sqrt{k_z^2 + k_\perp^2}$, $C \equiv \cos(\omega \Delta t)$
and $S \equiv \sin(\omega \Delta t) $. (See \cref{sec:PSTADderiv} for a
derivation of these equations.)

\section{Benchmarks}
\label{sec:benchmarks}

We developped a single-processor, proof-of-principle implementation of
the PIC algorithm described in the previous section (\cref{sec:implementation}), and tested
it in a number of physical situations. In particular, we emphasize
here the tests of the dispersion relation, since the absence of
spurious numerical dispersion was one of the original goals of this algorithm.

\subsection{Propagation in vacuum}
\label{sec:vacuum_vg}

A first test consisted in letting a laser pulse propagate in vacuum and in
measuring its group velocity in the simulation. These simulations were
run with the spectral cylindrical algorithm presented in
\cref{sec:implementation}, but also, for comparison, with a finite-difference cylindrical
algorithm equivalent to that of \cite{Lifschitz,Davidson} and which had
been previously implemented in the PIC code \textsc{Warp}.

The simulations were run with a moving window, in a box with a
longitudinal size of 40 $\mu$m and a transverse size of 48 $\mu$m. (In
the case of the spectral algorithm, the fields were damped at the back
of the moving window, in a similar way as in \citep{YuIPAC2015}.)
The laser pulse itself was initialized at focus, with a waist 
$w_0 = 16 \;\mathrm{\mu m}$, a length $L = 10 \; \mathrm{\mu m}$,
a wavelength $\lambda = 0.8 \; \mathrm{\mu m}$ and a 
dimensionless potential vector $a_0 = 10^{-2}$.
The resolution was varied while keeping the same cell aspect ratio ($\Delta r = 5\Delta z$). The
timestep was set to $c\Delta t = \Delta z$ in the case of the spectral
cylindrical algorithm and to $c\Delta t = 1/\sqrt{1/\Delta z^2 +
  2/\Delta r^2}$ in the case of the finite-difference
cylindrical algorithm (due to the existence of a Courant
limit for this algorithm). 

Physically, the on-axis group velocity of the pulse should be slightly lower than $c$ due
to the finite waist of the pulse (see e.g. \citet{Esarey1999}). The
analytical expression for the corresponding relative
difference in on-axis group velocity is
\begin{equation} 
\label{eq:vacuum_vg}
\frac{c-v_g}{c} = 2\left( \frac{\lambda}{2\pi w_0} \right)^2
\end{equation}
\noindent In the case at hand ($w_0=16\;\mathrm{\mu m}$,
$\lambda=0.8\;\mathrm{\mu m}$), this relative difference is extremely
small ($(c-v_g)/c = 1.27 \times 10^{-4}$), and it may be difficult for
PIC codes to capture this small physical difference. 

To assess the capacities of the finite-difference and
spectral cylindrical code in this regard, \cref{fig:Vacuum_vg} displays the relative
difference in group velocity, as measured in the
simulations. As can be expected, in the
finite-difference simulations, the
group velocity of the laser depends on the resolution, due to numerical
dispersion. 
Moreover, this group velocity is considerably different than the analytical
prediction, even for a relatively high resolution (40 gridpoints per
wavelength). On the other hand, with the spectral algorithm described
here, the group velocity is practically independent of the resolution, and
displays very good agreement with the analytical prediction. 
This corroborates the fact that the spectral cylindrical algorithm
described here has no numerical dispersion in vacuum.

\begin{figure}[!h]
\centering
\includegraphics[width=0.6\textwidth]{figures/Vacuum_vg.pdf}
\caption{\label{fig:Vacuum_vg}Relative difference between $c$ and the
group velocity of a laser pulse in vacuum, for different resolutions. The dashed line represents
the analytical prediction given by \cref{eq:vacuum_vg}, while the blue
and red points represent the results of PIC simulation, with the
spectral and finite-difference algorithm.}
\end{figure}


\subsection{Linear propagation in a plasma}
\label{sec:linear_plasma}

In order to confirm that the spectral algorithm also performs well in
the presence of a plasma, we ran the same type of simulations with a
uniform, pre-ionized plasma. The numerical parameters of the
simulations, as well as the physical parameters of the laser, 
were the same as in the previous subsection
(\cref{sec:vacuum_vg}). The plasma was represented by 16
macroparticles per cell, and had a density $n_e = 1.75\times
10^{18}\;\mathrm{cm}^{-3} = 10^{-3}\,n_c$, where $n_c$ is the critical
density for $\lambda=0.8\mathrm{\mu m}$.

Since the intensity of the laser is very low here ($a_0 = 10^{-2}$),
the propagation is linear, and the on-axis group velocity is given by
(e.g. \citep{Esarey1999})
\begin{equation} 
\label{eq:plasma_vg}
\frac{c-v_g}{c} = \frac{n_e}{2n_c} + 2\left( \frac{\lambda}{2\pi w_0} \right)^2
\end{equation}

In \cref{fig:Plasma_vg}, we compare this analytical prediction with the group velocity in the
finite-difference and spectral simulations. Again, the
group velocity is resolution-dependent in the finite-difference
algorithm, and it is substantial different than the analytical
prediction even at high resolution. In the spectral code, the group
velocity velocity exhibits a very weak dependence on resolution
(which is likely due to the errors of current deposition and field
gathering on the finite grid). However, its value remains always very
close to the analytical prediction at all resolutions.

\begin{figure}[!h]
\centering
\includegraphics[width=0.6\textwidth]{figures/Plasma_vg.pdf}
\caption{\label{fig:Plasma_vg}Relative difference between $c$ and the
group velocity of a laser pulse in a plasma at $10^{-3}\,n_c$, for different
resolutions. The dashed line represents
the analytical prediction given by \cref{eq:plasma_vg}, while the blue
and red points represent the results of PIC simulation.}
\end{figure}

We emphasize that, although the difference between $c$ and $v_g$ is
small here and may thus seem unimportant, it is this difference which determines
the dephasing length and thus the
maximum beam energy, in a laser-wakefield simulation. It is therefore
paramount to obtain its correct value in the simulation codes. This
problem is well-known in the case of standard finite-difference
codes. For Cartesian finite-difference codes, a common solution is to
use a scheme which is dispersion-free along the $z$ axis 
(e.g. \citep{Karkkainen,Pukhov,Nuter}), but no such scheme has been
developped for cylindrical codes. Alternatively, numerical dispersion is often 
dealt with in finite-difference codes by either using an even finer grid in
$z$ (which is very computationally expensive) or
a \emph{coarser} grid in $r$. (Recall that, in the simulations shown here, $\Delta r = 5\Delta
z$. A coarser resolution in $r$ allows to
use a larger timestep $\Delta t$, which improves numerical
dispersion.) However, a coarser resolution in $r$ may not always be
adapted to resolve the physics of interest. It is therefore remarkable 
that, with the spectral cylindrical algorithm, the correct group
velocity is obtained, even for a fine resolution in $r$. 

\subsection{Linear laser-wakefield}

In order further to ascertain that the spectral algorithm described here gives
appropriate results, we ran a simulation of a laser-wakefield, and
compared the amplitude of the wakefield with the corresponding analytical predictions.

In these simulations, the laser was linearly polarized along the
transverse $x$ direction, and had an amplitude $a_0 = 10^{-2}$, a
wavelength $\lambda=0.8 \;\mathrm{\mu m}$, a length $L=10\;\mathrm{\mu
m}$ and a waist $w_0 = 20\;\mathrm{\mu m}$. The simulation was run in
a moving window whose longitudinal and transverse sizes were $80 \;
\mathrm{\mu m}$ and $60 \; \mathrm{\mu m}$. The spatial and temporal
resolutions were $\Delta z = 0.05 \; \mathrm{\mu m}$, $\Delta r = 0.5
\;\mathrm{\mu m}$ and $\Delta t = \Delta z/c$. Since here $a_0 =
10^{-2}$, the analytical wakefield is given by
the linear and quasistatic theory. For a laser of the
form $a(z, r, t)= a_\ell(z, t) e^{-r^2/w_0^2} \cos(k_0z-\omega_0 t)$ --
where $a_\ell(z, t)$ is the longitudinal envelope of the laser -- the
longitudinal and transverse fields $E_z$ and $E_y$ are given by (e.g. \citep{EsareyRMP2009})
\begin{equation} 
E_z(z, r, t) = \frac{mc^2}{e} \frac{k_p^2}{4}\int_{z}^{\infty} 
a_\ell^2(z', t) e^{-r^2/w_0^2} \cos[k_p(z-z')]dz' 
\end{equation}
\begin{equation}
E_y(z, r, t) = -\frac{mc^2}{e} \frac{k_p y}{w_0^2}\int_{z}^{\infty} 
a_\ell^2(z', t) e^{-r^2/w_0^2} \sin[k_p(z-z')]dz' 
\end{equation}
\noindent where $k_p$ is the plasma wavevector.

Here, the longitudinal laser envelope $a_\ell$ was extracted directly from the
simulation, and the above analytical integrals where carried out
numerically. The resulting predicted $E_z$ and $E_y$ are plotted in dashed lines
in the left and right lower panels on \cref{fig:Linear_wkfld}
respectively. These predicted curves are compared with
the fields $E_z$ and $E_y$ extracted directly from the simulation (red
lines in the lower panels). The upper panels also show the fields $E_z$ and
$E_y$ from the simulation (red-blue colormaps), as well as the line
along which the fields in the lower panels are plotted (dashed line).

As can be seen on the lower panels of \cref{fig:Linear_wkfld}, the analytical and simulated
curves overlap very precisely. 



\begin{figure}[!h]
\centering
\includegraphics[width=\textwidth]{figures/Linear_wkfld.png}
\caption{\label{fig:Linear_wkfld} \comment{Add description}.}
\end{figure}


\section{Advantages over finite-difference codes}
\label{sec:advantages}



Mention obvious advantage with better numerical dispersion : dephasing
length will be better predicted (cite Cowan). 

Mention suffer from parallelization problems. + Moving window problems
\comment{Continue}

\subsection{Absence of numerical Cherenkov radiation for
  lab-frame simulations}

\comment{Fill the parameters}

\begin{figure}[!h]
\centering
\includegraphics[width=\textwidth]{figures/Cherenkov.png}
\caption{\label{fig:Cherenkov} At a similar time. \comment{Add description}.}
\end{figure}

\subsection{Accurate force of a laser on a relativistic electron}


\section*{Conclusion}

Few published codes have the above advantages in Cartesian geometry (aside
from spectral codes, directional splitting may have similar
advantages). Here on top of it, we have it in Circ.

\paragraph{Acknowledgements}

We thank Brendan Godfrey for valuable comments and suggestions. We
thank Andreas Maier's team in DESY, and in particular Manuel Kirchen,
for interesting discussions and for sharing computational ressources.

This work was supported by the Director, Office of Science, Office of High Energy Physics, U.S. Dept. of Energy under Contract No. DE-AC02-05CH11231, including from the Laboratory Directed Research and Development (LDRD) funding from Berkeley Lab.

This document was prepared as an account of work sponsored in part by the United States Government. While this document is believed to contain correct information, neither the United States Government nor any agency thereof, nor The Regents of the University of California, nor any of their employees, nor the authors makes any warranty, express or implied, or assumes any legal responsibility for the accuracy, completeness, or usefulness of any information, apparatus, product, or process disclosed, or represents that its use would not infringe privately owned rights. Reference herein to any specific commercial product, process, or service by its trade name, trademark, manufacturer, or otherwise, does not necessarily constitute or imply its endorsement, recommendation, or favoring by the United States Government or any agency thereof, or The Regents of the University of California. The views and opinions of authors expressed herein do not necessarily state or reflect those of the United States Government or any agency thereof or The Regents of the University of California.

\newpage
\appendix

\input{appendix.tex}

\bibliography{Bibliography}
\bibliographystyle{plainnat}

\end{document}
